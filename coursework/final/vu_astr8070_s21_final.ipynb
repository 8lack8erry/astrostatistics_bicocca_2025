{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ASTR 8070: Astrostatistics\n",
    "***S. R. Taylor***\n",
    "___\n",
    "\n",
    "# Final Exam [60 points total]\n",
    "### Available: Saturday, May 8th at 11am CDT\n",
    "### Due: Monday, May 10th at 11am CDT\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1 [30 points total]\n",
    "\n",
    "One of the most important revelations in modern cosmology was the accelerated expansion of the Universe, interpreted as being caused by a non-zero Cosmological Constant. In this question you will use a simulated sample of Type Ia supernovae to infer the composition of the Universe. \n",
    "\n",
    "1. Load in `astr8070_final_cosmodata.npy`, which can be found in the Github repo under `coursework/final/final_data`. The first column is the SN redshift, the second is the distance modulus, and the third is the Gaussian uncertainty on this distance modulus. Make a labeled scatter plot of the data. [2 points]\n",
    "\n",
    "\n",
    "2. Plot a line on top of this showing the relationship between the distance modulus and the redshift for the current concordance cosmology. You will need to look up the definition of the distance modulus, look up current reasonable cosmological parameters (cite your source), and plot the relationship. *Hint: check astropy.* [3 points]\n",
    "\n",
    "\n",
    "3. Create a log-likelihood function that reads in the data and accepts values for the Hubble constant, $H_0$, and the fractional energy density in matter, $\\Omega_M$. Assume a flat cosmological geometry, such that $\\Omega_M + \\Omega_\\Lambda=1$. Your function should take $H_0$ and $\\Omega_M$, and create a model for the distance moduli values at the redshifts of the samples, then compute the log-likelihood for the data. Print out the log-likelihood value at the cosmological parameter values that you used in (2). For maximum points, make sure your log-likelihood function is vectorized over the data samples. [6 points]\n",
    "\n",
    "\n",
    "4. Perform an MCMC with appropriate diagnostic checks (either manually yourself, or fine if performed by the sampler you employ) over the $\\{H_0, \\Omega_M\\}$ parameter space. Assume priors of $H_0 \\in U[50,100]$ km.s$^{-1}$.Mpc$^{-1}$, and $\\Omega_M \\in U[0,1]$. Make a labeled corner plot showing the $1$D and $2$D marginalized posterior probability distribution of these parameters. State the median value of the $1$D marginal posteriors for each, along with the values enclosing the $68\\%$ credible region. [8 points]\n",
    "\n",
    "\n",
    "5. Draw $100$ random samples from your posterior chain and plot the corresponding band of solutions that are consistent with the data on the distance-modulus--vs--redshift plot along with the original data. [4 points]\n",
    "\n",
    "\n",
    "6. Now, using an appropriate technique, find the Bayesian log-evidence of your $\\{H_0,\\Omega_M\\}$ model above. Also find the log-evidence of a model with $\\Omega_M=1$ such that $H_0$ is the only varied parameter. What is the Bayes factor for the presence of a Cosmological Constant given these data? [7 points] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2 [30 points total]\n",
    "\n",
    "There are several empirical scaling relationships between the masses of black holes in galaxy centers and the properties of their hosts. In this problem you will use real data from the \"MASSIVE\" Galaxy Survey. This data updates that used in [McConnell & Ma (2013)](https://ui.adsabs.harvard.edu/abs/2013ApJ...764..184M/abstract), which presented a systematic investigation of scaling relations with different catalog subsets.\n",
    "\n",
    "1. Download this dataset: http://blackhole.berkeley.edu/wp-content/uploads/2016/09/current_ascii.txt. Skip the appropriate header rows and read this into a `pandas` dataframe. Use the meta-data in the header rows to create appropriate column names for your dataframe. Make sure that your data file is properly formatted with tab-spaced columns so that it is readable without errors. [3 points]\n",
    "\n",
    "\n",
    "2. Create a data matrix out of the base-10 log values of: the galaxy distance, the velocity dispersion $\\sigma$, and the black hole mass. Create a target vector that has $1$ for early-type galaxies (morphology has `E` or `S0` in the value) and $0$ for late-type galaxies. Print out the number of early-type and late-type galaxies that are in your target vector, as well as the total number of galaxies. [3 points]\n",
    "\n",
    "\n",
    "3. Perform a 50-50 train-test split on the data matrix and target vector, using `random_state=0` for reproducibility. Train the following classifiers, overplotting ROC curves for all:\n",
    "    - Gaussian Naive Bayes\n",
    "    - LDA\n",
    "    - QDA\n",
    "    - $K$-nearest neighbors (with $K=10$)\n",
    "    - Gaussian mixture model (with $2$ components)\n",
    "    - Decision Tree (with `entropy` criterion, and tree depth $=2$)\n",
    " [5 points]\n",
    "    \n",
    "\n",
    "4. What minimum tree depth do you need to achieve essentially perfect classification accuracy with the Decision Tree? Confirm this by making a two-panel figure with scatter plots of the log10-distance and log10-sigma from the test data, color-coded by the test label (left panel) and predicted label (right panel).  [3 points]\n",
    "\n",
    "\n",
    "5. The following regression tasks should all produce best-fit regression coefficients and a plot. State how many galaxies are being fit in each scenario.\n",
    "    - Use the $68\\%$ low and high black-hole mass values to deduce the uncertainty on each $(M_\\mathrm{BH}/M_\\odot)$. Convert this into an uncertainty on $\\log_{10}(M_\\mathrm{BH}/M_\\odot)$. Ignoring the uncertainties on $\\sigma$, perform linear regression of the form\n",
    "$$ \\log_{10}(M_\\mathrm{BH}/M_\\odot) = \\alpha + \\beta\\log_{10}(\\sigma \\,/\\, 200\\,\\mathrm{km.s}^{-1})$$\n",
    "and state the best-fit regression coefficients $\\{\\alpha,\\beta\\}$. Plot the best-fit line on a scatter plot with the data. \n",
    "    - Repeat the previous bullet to fit and plot the relation $$ \\log_{10}(M_\\mathrm{BH}/M_\\odot) = \\alpha + \\beta\\log_{10}(L_V \\,/\\, 10^{11}L_\\odot)$$ for the sub-sample of galaxies with $V$-band luminosity data (ignoring the $L_V$ uncertainties).\n",
    "    - Repeat to fit and plot the relation $$ \\log_{10}(M_\\mathrm{BH}/M_\\odot) = \\alpha + \\beta\\log_{10}(M_\\mathrm{bulge} \\,/\\, 10^{11}M_\\odot)$$ for the sub-sample of galaxies with bulge mass measurements (ignoring the $M_\\mathrm{bulge}$ uncertainties).\n",
    " [7 points]\n",
    " \n",
    " \n",
    "6. Perform polynomial regression of the form\n",
    "$$ \\log_{10}(M_\\mathrm{BH}/M_\\odot) = \\alpha + \\sum_{p=1}^{N_p}\\beta_p[\\log_{10}(\\sigma \\,/\\, 200\\,\\mathrm{km.s}^{-1})]^p.$$\n",
    "For $N_p$ in the range $0$ to $5$, fit the polynomial relationship, print the regression coefficients, and compute the BIC value. Make a labeled plot of the BIC versus the polynomial degree. Is a quadratic or higher polynomial relationship between $\\log_{10}(M_\\mathrm{BH}/M_\\odot)$ and $\\log_{10}(\\sigma \\,/\\, 200\\,\\mathrm{km.s}^{-1})$ favored? [5 points]\n",
    "\n",
    "\n",
    "7. Perform linear regression ($N_p=1$) on the dataset on sub-samples of early-type and late-type galaxies. Print the best-fit regression coefficients from each of these sub-sets. Make a scatter plot that includes the original data color coded by early/late type, the fit to all of the data, and the fits from the early/late-type sub-samples. The plot should have appropriate labels and a legend. [4 points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:astr8070] *",
   "language": "python",
   "name": "conda-env-astr8070-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
